# -*- coding: utf-8 -*-
"""rainfall_prediction_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IbdyhZ80uLiq6XSVwTjloBZHWCUZrH0x
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.cluster import KMeans

# Load your dataset
dataset = pd.read_csv("/content/weatherAUS (1).csv")

# Extract necessary columns
X = dataset.iloc[:, [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]].values
Y = dataset.iloc[:, -1].values

# Ensure Y is a column vector
Y = Y.reshape(-1, 1)

# Handle missing data
imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')
X = imputer.fit_transform(X)
Y = imputer.fit_transform(Y)

# Label Encoding
le1 = LabelEncoder()
X[:, 0] = le1.fit_transform(X[:, 0])
le2 = LabelEncoder()
X[:, 4] = le2.fit_transform(X[:, 4])
le3 = LabelEncoder()
X[:, 6] = le1.fit_transform(X[:, 6])
le4 = LabelEncoder()
X[:, 7] = le2.fit_transform(X[:, 7])
le5 = LabelEncoder()
X[:, -1] = le2.fit_transform(X[:, -1])
le6 = LabelEncoder()
Y = le6.fit_transform(Y.ravel())

# Feature Scaling
sc = StandardScaler()
X = sc.fit_transform(X)

# Function to determine season based on month
def month_to_season(month):
    if month in [12, 1, 2]:
        return 'Summer'
    elif month in [3, 4, 5]:
        return 'Autumn'
    elif month in [6, 7, 8]:
        return 'Winter'
    else:
        return 'Spring'

# Add season column
dataset['Date'] = pd.to_datetime(dataset['Date'], format='%Y-%m-%d')
dataset['Month'] = dataset['Date'].dt.month
dataset['Season'] = dataset['Month'].apply(month_to_season)

# Convert seasons to numerical values
season_le = LabelEncoder()
dataset['Season'] = season_le.fit_transform(dataset['Season'])

# Add season to X
X = np.concatenate((X, dataset[['Season']].values), axis=1)

# Split the dataset
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)

# Function to perform seasonal clustering
def seasonal_clustering(X):
    kmeans = KMeans(n_clusters=4, random_state=0)
    clusters = kmeans.fit_predict(X[:, -1].reshape(-1, 1))  # Using Season column for clustering
    return clusters

# Apply seasonal clustering
seasonal_clusters_train = seasonal_clustering(X_train)
seasonal_clusters_test = seasonal_clustering(X_test)

# Train separate models for each seasonal cluster
models = {}
for cluster in range(4):
    cluster_indices = np.where(seasonal_clusters_train == cluster)[0]
    X_cluster = X_train[cluster_indices]
    Y_cluster = Y_train[cluster_indices]

    model = RandomForestClassifier(n_estimators=150, random_state=0)
    model.fit(X_cluster, Y_cluster)
    models[cluster] = model

# Make predictions using the appropriate model for each data point
y_pred_clustered = np.zeros(X_test.shape[0])
for cluster in range(4):
    cluster_indices = np.where(seasonal_clusters_test == cluster)[0]
    X_cluster = X_test[cluster_indices]

    if len(cluster_indices) > 0:
        model = models[cluster]
        y_pred_clustered[cluster_indices] = model.predict(X_cluster)

# Convert predictions back to 'Yes' or 'No'
y_pred_clustered = le6.inverse_transform(y_pred_clustered.astype(int))

# Create DataFrame for predictions
prediction_df = pd.DataFrame({'Rain on Tomorrow': le6.inverse_transform(Y_test), 'Prediction of Rain': y_pred_clustered})

# Print prediction DataFrame
print(prediction_df)

# Print accuracy score
print("Accuracy Score:", accuracy_score(Y_test, le6.transform(y_pred_clustered)))

# Save predictions to CSV
prediction_df.to_csv('prediction.csv', index=False)

# Visualization 1: Distribution of Seasons
plt.figure(figsize=(10, 6))
sns.countplot(x='Season', data=dataset)
plt.title('Distribution of Seasons')
plt.xlabel('Season')
plt.ylabel('Count')
plt.show()

# Visualization 2: Accuracy by Season
season_accuracy = []
for cluster in range(4):
    cluster_indices = np.where(seasonal_clusters_test == cluster)[0]
    if len(cluster_indices) > 0:
        y_true_cluster = Y_test[cluster_indices]
        y_pred_cluster = le6.transform(y_pred_clustered[cluster_indices])
        accuracy = accuracy_score(y_true_cluster, y_pred_cluster)
        season_accuracy.append((season_le.inverse_transform([cluster])[0], accuracy))

season_accuracy_df = pd.DataFrame(season_accuracy, columns=['Season', 'Accuracy'])
plt.figure(figsize=(10, 6))
sns.barplot(x='Season', y='Accuracy', data=season_accuracy_df)
plt.title('Prediction Accuracy by Season')
plt.xlabel('Season')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
plt.show()

# Visualization 3: Feature Importance from the Random Forest model of the first cluster (for demonstration)
importances = models[0].feature_importances_
feature_names = list(dataset.columns[[1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]]) + ['Season']

plt.figure(figsize=(12, 8))
sns.barplot(x=importances, y=feature_names)
plt.title('Feature Importance from Random Forest Model (Cluster 0)')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.show()